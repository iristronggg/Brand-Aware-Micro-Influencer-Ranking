{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6876c3fd",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6ba77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:12:56.217991Z",
     "start_time": "2023-07-10T01:12:56.096979Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521d65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:38.453332Z",
     "start_time": "2023-07-07T05:06:38.450507Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current process ID (PID)\n",
    "pid = os.getpid()\n",
    "\n",
    "print(\"Current Process ID:\", pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb5e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:40.856360Z",
     "start_time": "2023-07-07T05:06:39.770927Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "# from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e2b02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T10:59:44.768442Z",
     "start_time": "2023-07-05T10:59:44.766418Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.multiprocessing.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232602f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:43.612108Z",
     "start_time": "2023-07-07T05:06:43.605527Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028852c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:44.565123Z",
     "start_time": "2023-07-07T05:06:44.353494Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15899b98",
   "metadata": {},
   "source": [
    "# Load Mapping Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae625c",
   "metadata": {},
   "source": [
    "train / test 的 brand / inf ID，以及我有轉成另一種 node ID，是 train 的 brand / inf 一起編號，test 亦然。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf546a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:51.058453Z",
     "start_time": "2023-07-07T05:06:51.055483Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"discover_train_brand_index.pickle\", 'rb') as f:\n",
    "    train_brand_ids = pickle.load(f)\n",
    "with open(\"discover_test_brand_index.pickle\", 'rb') as f:\n",
    "    test_brand_ids = pickle.load(f)\n",
    "with open(\"discover_train_inf_index.pickle\", 'rb') as f:\n",
    "    train_inf_ids = pickle.load(f)\n",
    "with open(\"discover_test_inf_index.pickle\", 'rb') as f:\n",
    "    test_inf_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c99e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:51.558269Z",
     "start_time": "2023-07-07T05:06:51.554957Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"train_test_split/train_node_brand_id.pkl\", 'rb') as f:\n",
    "    train_node_brand_id = pickle.load(f)\n",
    "with open(\"train_test_split/train_node_inf_id.pkl\", 'rb') as f:\n",
    "    train_node_inf_id = pickle.load(f)\n",
    "with open(\"train_test_split/test_node_brand_id.pkl\", 'rb') as f:\n",
    "    test_node_brand_id = pickle.load(f)\n",
    "with open(\"train_test_split/test_node_inf_id.pkl\", 'rb') as f:\n",
    "    test_node_inf_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee8fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:52.082049Z",
     "start_time": "2023-07-07T05:06:52.077501Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"train_test_split/train_brand_node_id.pkl\", 'rb') as f:\n",
    "    train_brand_node_id = pickle.load(f)\n",
    "with open(\"train_test_split/train_inf_node_id.pkl\", 'rb') as f:\n",
    "    train_inf_node_id = pickle.load(f)\n",
    "with open(\"train_test_split/test_brand_node_id.pkl\", 'rb') as f:\n",
    "    test_brand_node_id = pickle.load(f)\n",
    "with open(\"train_test_split/test_inf_node_id.pkl\", 'rb') as f:\n",
    "    test_inf_node_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a06f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:52.739200Z",
     "start_time": "2023-07-07T05:06:52.736730Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('sorted_360_brand_list.pkl', 'rb') as f:\n",
    "    all_brands = pickle.load(f)\n",
    "with open('sorted_3748_inf_list.pkl', 'rb') as f:\n",
    "    all_infs = pickle.load(f)\n",
    "with open('category_list.pickle', 'rb') as f:\n",
    "    category_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15341f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T05:06:53.392882Z",
     "start_time": "2023-07-07T05:06:53.390883Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_BRAND_NUM = 286\n",
    "TRAIN_INF_NUM = 3075\n",
    "TEST_BRAND_NUM = 74\n",
    "TEST_INF_NUM = 797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44d03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd83b7b1",
   "metadata": {},
   "source": [
    "# Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce162a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_list = np.load('train_test_split/train_label_list_with_category.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d153f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_num = 3\n",
    "hard_neg_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4691ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_on_the_fly(brand_node_id, label_list, neg_num=neg_num, hard_neg_num=hard_neg_num):\n",
    "    \"\"\"\n",
    "    return a list of brand samples, each mapping to a brand\n",
    "    a sample looks like [pos, neg, neg, neg, hard_neg]\n",
    "    each brand has several (not fixed) number of samples\n",
    "    \"\"\"\n",
    "    # labels = label_list[brand_node_id]\n",
    "    all_negative_indices_sampled = []\n",
    "    all_hard_neg_indices_sampled = []\n",
    "    all_brand_samples = []\n",
    "    \n",
    "    for i in range(brand_node_id.shape[0]):\n",
    "        brand_samples = []\n",
    "        label = label_list[brand_node_id[i]]\n",
    "        positive_indices = torch.nonzero(label == 1).squeeze(1)\n",
    "        negative_indices = torch.nonzero((label == 0) | (label == 2)).squeeze(1)\n",
    "        hard_neg_indices = torch.nonzero(label == 2).squeeze(1)\n",
    "\n",
    "        num_positive_samples = len(positive_indices)\n",
    "        num_negative_samples = len(negative_indices)\n",
    "        num_hard_neg_samples = len(hard_neg_indices)\n",
    "        # print(num_positive_samples, num_negative_samples, num_hard_neg_samples)\n",
    "\n",
    "        for j in range(num_positive_samples):\n",
    "            # print(positive_indices[j])\n",
    "            negative_indices_sampled = torch.randperm(num_negative_samples)[:neg_num]\n",
    "            negative_indices_sampled = negative_indices[negative_indices_sampled]\n",
    "            hard_neg_indices_sampled = torch.randperm(num_hard_neg_samples)[:hard_neg_num]\n",
    "            hard_neg_indices_sampled = hard_neg_indices[hard_neg_indices_sampled]\n",
    "\n",
    "            all_negative_indices_sampled.append(negative_indices_sampled)\n",
    "            all_hard_neg_indices_sampled.append(hard_neg_indices_sampled)\n",
    "\n",
    "            four_comb = torch.cat((torch.tensor([positive_indices[j]]).to(device), negative_indices_sampled, hard_neg_indices_sampled))\n",
    "            brand_samples.append(four_comb)\n",
    "        brand_samples = torch.stack(brand_samples)\n",
    "        all_brand_samples.append(brand_samples)\n",
    "    # all_brand_samples = torch.stack(all_brand_samples)\n",
    "\n",
    "    return all_brand_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa583a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 變成 [brand, pos, (hard)neg] 的 triplet\n",
    "\n",
    "n_samples = 5\n",
    "five_times = np.array([])\n",
    "for k in range(n_samples):\n",
    "    tt = sampling_on_the_fly(torch.arange(0, TRAIN_BRAND_NUM).to(device), torch.from_numpy(train_label_list).to(device), 3, 1)\n",
    "#     print(tt)\n",
    "\n",
    "    all_hard_samples = []\n",
    "    for brand_id, brand_samples in enumerate(tt):\n",
    "        for i in range(brand_samples.shape[0]): # pos inf number\n",
    "            for j in range(1, 5):\n",
    "                all_samples = []\n",
    "                all_samples.append(brand_id) # brand node id\n",
    "                all_samples.append(brand_samples[i][0].item()) # positive inf node id\n",
    "                all_samples.append(brand_samples[i][j].item())\n",
    "                all_hard_samples.append(all_samples)\n",
    "#     print(all_hard_samples)\n",
    "\n",
    "    all_hard_samples = torch.tensor(all_hard_samples)\n",
    "#     print(all_hard_samples.shape)\n",
    "\n",
    "    all_hard_samples = all_hard_samples.numpy()\n",
    "    \n",
    "    if k == 0:\n",
    "        five_times = all_hard_samples\n",
    "    else:\n",
    "        five_times = np.concatenate((five_times, all_hard_samples), axis=0)\n",
    "    print(five_times.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21c80a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Handle Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa47a36",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Text - LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b6a2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "因為 train/test 時已經把 50 篇的字接在一起再斷詞了，所以不需再做 history pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075a5f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T19:14:54.413676Z",
     "start_time": "2023-06-08T19:14:54.402920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_lda = np.load('lda/lda_topic19_it50_train_pred.npy')\n",
    "test_lda = np.load('lda/lda_topic19_it50_test_pred.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd059cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T19:27:56.342465Z",
     "start_time": "2023-06-08T19:27:56.338269Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_lda.shape, test_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859014af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T19:38:12.791929Z",
     "start_time": "2023-06-08T19:38:12.779308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_lda = [0] * TRAIN_BRAND_NUM\n",
    "train_inf_lda = [0] * TRAIN_INF_NUM\n",
    "for i in range(train_lda.shape[0]):\n",
    "    if i < TRAIN_BRAND_NUM:   # brand\n",
    "        aid = train_brand_ids[i]\n",
    "        nid = train_brand_node_id[aid]\n",
    "        train_brand_lda[nid] = train_lda[i]\n",
    "    else:   # inf\n",
    "        aid = train_inf_ids[i-TRAIN_BRAND_NUM]\n",
    "        nid = train_inf_node_id[aid]-TRAIN_BRAND_NUM\n",
    "        train_inf_lda[nid] = train_lda[i]\n",
    "train_brand_lda = np.array(train_brand_lda)\n",
    "train_inf_lda = np.array(train_inf_lda)\n",
    "len(train_brand_lda), len(train_inf_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65e586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T19:42:19.856939Z",
     "start_time": "2023-06-08T19:42:19.851568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_lda.shape, train_inf_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c2d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T19:39:01.848450Z",
     "start_time": "2023-06-08T19:39:01.845230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(286):\n",
    "    if type(train_brand_lda[i]) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4f9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T19:39:17.553157Z",
     "start_time": "2023-06-08T19:39:17.548923Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(3075):\n",
    "    if type(train_inf_lda[i]) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758db69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:27:32.291806Z",
     "start_time": "2023-06-08T20:27:32.282417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_brand_lda = [0] * TEST_BRAND_NUM\n",
    "test_inf_lda = [0] * TEST_INF_NUM\n",
    "for i in range(test_lda.shape[0]):\n",
    "    if i < TEST_BRAND_NUM:   # brand\n",
    "        aid = test_brand_ids[i]\n",
    "        nid = test_brand_node_id[aid]\n",
    "        test_brand_lda[nid] = test_lda[i]\n",
    "    else:   # inf\n",
    "        aid = test_inf_ids[i-TEST_BRAND_NUM]\n",
    "        nid = test_inf_node_id[aid]-TEST_BRAND_NUM\n",
    "        test_inf_lda[nid] = test_lda[i]\n",
    "test_brand_lda = np.array(test_brand_lda)\n",
    "test_inf_lda = np.array(test_inf_lda)\n",
    "len(test_brand_lda), len(test_inf_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2beab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:27:37.273591Z",
     "start_time": "2023-06-08T20:27:37.269397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_brand_lda.shape, test_inf_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89634567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:27:39.282878Z",
     "start_time": "2023-06-08T20:27:39.279814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(TEST_BRAND_NUM):\n",
    "    if type(test_brand_lda[i]) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d383583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:27:39.778471Z",
     "start_time": "2023-06-08T20:27:39.774727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(TEST_INF_NUM):\n",
    "    if type(test_inf_lda[i]) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68f91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:27:51.576647Z",
     "start_time": "2023-06-08T20:27:51.569859Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(train_brand_lda), 'train_test_split/train_brand_text_feature_lda.pt')\n",
    "torch.save(torch.from_numpy(train_inf_lda), 'train_test_split/train_inf_text_feature_lda.pt')\n",
    "torch.save(torch.from_numpy(test_brand_lda), 'train_test_split/test_brand_text_feature_lda.pt')\n",
    "torch.save(torch.from_numpy(test_inf_lda), 'train_test_split/test_inf_text_feature_lda.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99b5a9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815a0a0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Upernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b8164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:12:21.616333Z",
     "start_time": "2023-06-08T20:12:21.611055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def img_preprocess(img_feat, thres=0.1):\n",
    "    \"\"\" \n",
    "    filter insignificant class by thres -> 0\n",
    "    \"\"\"\n",
    "\n",
    "    # Use boolean indexing to select elements above threshold\n",
    "    above_threshold = img_feat > thres\n",
    "\n",
    "    # Zero out the elements below the threshold\n",
    "    filtered_output = torch.zeros_like(img_feat)\n",
    "    filtered_output[above_threshold] = img_feat[above_threshold]\n",
    "    \n",
    "    # sum across 50 history posts\n",
    "    filtered_output_sum = torch.sum(filtered_output, dim=0)\n",
    "    \n",
    "    # l2 normalization -> sum not 1\n",
    "#     l2_norm = torch.norm(filtered_output_sum, p=2)\n",
    "#     normalized_output = filtered_output_sum / l2_norm\n",
    "\n",
    "    # softmax\n",
    "    softmax_output = F.softmax(filtered_output_sum, dim=0)\n",
    "\n",
    "    return softmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a93c8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T19:47:53.189665Z",
     "start_time": "2023-06-08T19:47:53.186889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b_folder = 'image_vgg/unifiedparsing/new_brand_result/'\n",
    "i_folder = 'image_vgg/unifiedparsing/new_inf_result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c189af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:13:16.660618Z",
     "start_time": "2023-06-08T20:13:16.372795Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_brand_upernet_pre = [0]*360\n",
    "for i, a in enumerate(all_brands):\n",
    "    a_img = np.load(b_folder+a+'.npy')\n",
    "    a_img_pre = img_preprocess(torch.from_numpy(a_img))\n",
    "    all_brand_upernet_pre[i] = a_img_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9bb3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:13:28.413746Z",
     "start_time": "2023-06-08T20:13:28.408612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(360):\n",
    "    if type(all_brand_upernet_pre[i]) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e959806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:14:49.005043Z",
     "start_time": "2023-06-08T20:14:43.081320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_inf_upernet_pre = [0]*len(all_infs)\n",
    "for i, a in enumerate(all_infs):\n",
    "    a_img = np.load(i_folder+a+'.npy')\n",
    "    a_img_pre = img_preprocess(torch.from_numpy(a_img))\n",
    "    all_inf_upernet_pre[i] = a_img_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0325001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:33:52.382971Z",
     "start_time": "2023-06-08T20:33:52.378944Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(all_inf_upernet_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2488783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:34:06.574749Z",
     "start_time": "2023-06-08T20:34:06.570550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_infs)):\n",
    "    if type(all_inf_upernet_pre[i]) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854d06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:23:05.651748Z",
     "start_time": "2023-06-08T22:23:05.283023Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(all_brand_upernet_pre, 'train_test_split/all_brand_upernet_preprocessed.pt')\n",
    "torch.save(all_inf_upernet_pre, 'train_test_split/all_inf_upernet_preprocessed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0accce7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:23:30.839143Z",
     "start_time": "2023-06-08T20:23:30.832536Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_upernet = [0]*TRAIN_BRAND_NUM\n",
    "test_brand_upernet = [0]*TEST_BRAND_NUM\n",
    "for i in range(len(all_brands)):\n",
    "    if i in train_brand_ids:\n",
    "        nid = train_brand_node_id[i]\n",
    "        train_brand_upernet[nid] = all_brand_upernet_pre[i]\n",
    "    if i in test_brand_ids:\n",
    "        nid = test_brand_node_id[i]\n",
    "        test_brand_upernet[nid] = all_brand_upernet_pre[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038a452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:24:08.775578Z",
     "start_time": "2023-06-08T20:24:08.772056Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for t in train_brand_upernet:\n",
    "    if type(t) == int:\n",
    "        print(t)\n",
    "for t in test_brand_upernet:\n",
    "    if type(t) == int:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8788edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:46:19.625526Z",
     "start_time": "2023-06-08T20:46:19.547540Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inf_upernet = [0]*TRAIN_INF_NUM\n",
    "test_inf_upernet = [0]*TEST_INF_NUM\n",
    "\n",
    "for i in range(len(all_infs)):\n",
    "    if i in train_inf_ids:\n",
    "        nid = train_inf_node_id[i] - TRAIN_BRAND_NUM\n",
    "        if nid < 0:\n",
    "            print(i)\n",
    "        train_inf_upernet[nid] = all_inf_upernet_pre[i]\n",
    "    if i in test_inf_ids:  ## 注意！ train / test inf 有重複，所以不能用 elif\n",
    "        nid = test_inf_node_id[i] - TEST_BRAND_NUM\n",
    "        if nid < 0:\n",
    "            print(i)\n",
    "        test_inf_upernet[nid] = all_inf_upernet_pre[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefea985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:46:28.430041Z",
     "start_time": "2023-06-08T20:46:28.424131Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for t in train_inf_upernet:\n",
    "    if type(t) == int:\n",
    "        print(t)\n",
    "for i, t in enumerate(test_inf_upernet):\n",
    "    if type(t) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae083f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:47:27.234096Z",
     "start_time": "2023-06-08T20:47:27.226384Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_upernet = torch.stack(train_brand_upernet)\n",
    "test_brand_upernet = torch.stack(test_brand_upernet)\n",
    "train_inf_upernet = torch.stack(train_inf_upernet)\n",
    "test_inf_upernet = torch.stack(test_inf_upernet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ea457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:47:44.531039Z",
     "start_time": "2023-06-08T20:47:44.524998Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_upernet.shape, test_brand_upernet.shape, train_inf_upernet.shape, test_inf_upernet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7610d21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T20:48:33.969781Z",
     "start_time": "2023-06-08T20:48:33.952642Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(train_brand_upernet, 'train_test_split/train_brand_upernet.pt')\n",
    "torch.save(test_brand_upernet, 'train_test_split/test_brand_upernet.pt')\n",
    "torch.save(train_inf_upernet, 'train_test_split/train_inf_upernet.pt')\n",
    "torch.save(test_inf_upernet, 'train_test_split/test_inf_upernet.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ccb389",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974a47b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:13:58.301132Z",
     "start_time": "2023-06-08T22:13:58.046879Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load image features\n",
    "brand_post_images_resnet101 = np.load(\"image_vgg/brand_post_images_resnet101.npy\")\n",
    "\n",
    "with open(\"image_vgg/inf_post_images_resnet101_gpu.pickle\", 'rb') as f:\n",
    "    inf_post_images_resnet101 = pickle.load(f) # dict\n",
    "\n",
    "brand_post_images_resnet101.shape, len(inf_post_images_resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a4a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:17:49.666169Z",
     "start_time": "2023-06-08T22:17:49.419635Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_brand_resnet = [0]*360\n",
    "for i in range(360):\n",
    "    img_pre = img_preprocess(torch.from_numpy(brand_post_images_resnet101[i]))\n",
    "    if img_pre.shape[0] != 1000:\n",
    "        print(i)\n",
    "    all_brand_resnet[i] = img_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ef63a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:18:11.516997Z",
     "start_time": "2023-06-08T22:18:11.511782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for t in all_brand_resnet:\n",
    "    if type(t) == int:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14336a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:22:15.169242Z",
     "start_time": "2023-06-08T22:22:15.163992Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(list(inf_post_images_resnet101.keys())) == list(range(len(all_infs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e7039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:20:46.293530Z",
     "start_time": "2023-06-08T22:20:43.809255Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_inf_resnet = [0]*len(all_infs)\n",
    "for i in range(len(all_infs)):\n",
    "    if inf_post_images_resnet101[i].shape != (50, 1000):\n",
    "        print(i)\n",
    "    img_pre = img_preprocess(torch.from_numpy(inf_post_images_resnet101[i]))\n",
    "    if img_pre.shape[0] != 1000:\n",
    "        print(i)\n",
    "    all_inf_resnet[i] = img_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa750728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:23:29.034699Z",
     "start_time": "2023-06-08T22:23:28.922795Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(all_brand_resnet, 'train_test_split/all_brand_resnet_preprocessed.pt')\n",
    "torch.save(all_inf_resnet, 'train_test_split/all_inf_resnet_preprocessed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c8d08",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c69a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:29:38.465813Z",
     "start_time": "2023-06-08T22:29:38.460313Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_resnet = [0]*TRAIN_BRAND_NUM\n",
    "test_brand_resnet = [0]*TEST_BRAND_NUM\n",
    "for i in range(len(all_brands)):\n",
    "    if i in train_brand_ids:\n",
    "        nid = train_brand_node_id[i]\n",
    "        train_brand_resnet[nid] = all_brand_resnet[i]\n",
    "    if i in test_brand_ids:\n",
    "        nid = test_brand_node_id[i]\n",
    "        test_brand_resnet[nid] = all_brand_resnet[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff090b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:29:38.995337Z",
     "start_time": "2023-06-08T22:29:38.991784Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for t in train_brand_resnet:\n",
    "    if type(t) == int:\n",
    "        print(t)\n",
    "for t in test_brand_resnet:\n",
    "    if type(t) == int:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4feb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:29:39.656197Z",
     "start_time": "2023-06-08T22:29:39.528323Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inf_resnet = [0]*TRAIN_INF_NUM\n",
    "test_inf_resnet = [0]*TEST_INF_NUM\n",
    "\n",
    "for i in range(len(all_infs)):\n",
    "    if i in train_inf_ids:\n",
    "        nid = train_inf_node_id[i] - TRAIN_BRAND_NUM\n",
    "        if nid < 0:\n",
    "            print(i)\n",
    "        train_inf_resnet[nid] = all_inf_resnet[i]\n",
    "    if i in test_inf_ids:\n",
    "        nid = test_inf_node_id[i] - TEST_BRAND_NUM\n",
    "        if nid < 0:\n",
    "            print(i)\n",
    "        test_inf_resnet[nid] = all_inf_resnet[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a86d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:29:39.967880Z",
     "start_time": "2023-06-08T22:29:39.962945Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for t in train_inf_resnet:\n",
    "    if type(t) == int:\n",
    "        print(t)\n",
    "for i, t in enumerate(test_inf_resnet):\n",
    "    if type(t) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed70d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:29:40.670026Z",
     "start_time": "2023-06-08T22:29:40.653879Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_resnet = torch.stack(train_brand_resnet)\n",
    "test_brand_resnet = torch.stack(test_brand_resnet)\n",
    "train_inf_resnet = torch.stack(train_inf_resnet)\n",
    "test_inf_resnet = torch.stack(test_inf_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a2fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:29:42.415679Z",
     "start_time": "2023-06-08T22:29:42.411215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_resnet.shape, test_brand_resnet.shape, train_inf_resnet.shape, test_inf_resnet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e9166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:30:11.736710Z",
     "start_time": "2023-06-08T22:30:11.698581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(train_brand_resnet, 'train_test_split/train_brand_resnet.pt')\n",
    "torch.save(test_brand_resnet, 'train_test_split/test_brand_resnet.pt')\n",
    "torch.save(train_inf_resnet, 'train_test_split/train_inf_resnet.pt')\n",
    "torch.save(test_inf_resnet, 'train_test_split/test_inf_resnet.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a31d9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067d11f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:33:32.074661Z",
     "start_time": "2023-06-08T22:33:31.978030Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_mor_image_feature = torch.cat((train_brand_resnet, train_brand_upernet), dim=1)\n",
    "test_brand_mor_image_feature = torch.cat((test_brand_resnet, test_brand_upernet), dim=1)\n",
    "train_inf_mor_image_feature = torch.cat((train_inf_resnet, train_inf_upernet), dim=1)\n",
    "test_inf_mor_image_feature = torch.cat((test_inf_resnet, test_inf_upernet), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b787b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:33:43.834628Z",
     "start_time": "2023-06-08T22:33:43.830445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_brand_mor_image_feature.shape, test_brand_mor_image_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5815177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:33:55.437904Z",
     "start_time": "2023-06-08T22:33:55.433698Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_inf_mor_image_feature.shape, test_inf_mor_image_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51914e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T22:35:20.657431Z",
     "start_time": "2023-06-08T22:35:20.608346Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(train_brand_mor_image_feature, 'train_test_split/train_brand_mor_image_feature.pt')\n",
    "torch.save(train_inf_mor_image_feature, 'train_test_split/train_inf_mor_image_feature.pt')\n",
    "torch.save(test_brand_mor_image_feature, 'train_test_split/test_brand_mor_image_feature.pt')\n",
    "torch.save(test_inf_mor_image_feature, 'train_test_split/test_inf_mor_image_feature.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb0c06",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0b667d",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598539c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T10:59:51.416223Z",
     "start_time": "2023-07-05T10:59:51.380317Z"
    }
   },
   "outputs": [],
   "source": [
    "train_brand_text_feature = torch.load('train_test_split/train_brand_text_feature_lda.pt')\n",
    "train_inf_text_feature = torch.load('train_test_split/train_inf_text_feature_lda.pt')\n",
    "test_brand_text_feature = torch.load('train_test_split/test_brand_text_feature_lda.pt')\n",
    "test_inf_text_feature = torch.load('train_test_split/test_inf_text_feature_lda.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a13558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T10:59:52.610863Z",
     "start_time": "2023-07-05T10:59:52.542442Z"
    }
   },
   "outputs": [],
   "source": [
    "train_brand_image_feature = torch.load('train_test_split/train_brand_mor_image_feature.pt')\n",
    "train_inf_image_feature = torch.load('train_test_split/train_inf_mor_image_feature.pt')\n",
    "test_brand_image_feature = torch.load('train_test_split/test_brand_mor_image_feature.pt')\n",
    "test_inf_image_feature = torch.load('train_test_split/test_inf_mor_image_feature.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345a020",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:33.471243Z",
     "start_time": "2023-07-05T17:01:33.466266Z"
    }
   },
   "outputs": [],
   "source": [
    "train_brand_node_emb = torch.load('train_test_split/train_brand_hashtag_weighted_nod2vec_0615_r1_sqrt.pt')\n",
    "test_brand_node_emb = torch.load('train_test_split/test_brand_hashtag_weighted_nod2vec_0615_r1_sqrt.pt')\n",
    "train_inf_node_emb = torch.load('train_test_split/train_inf_hashtag_weighted_nod2vec_0615_r1_sqrt.pt')\n",
    "test_inf_node_emb = torch.load('train_test_split/test_inf_hashtag_weighted_nod2vec_0615_r1_sqrt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77d8a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T14:19:57.966873Z",
     "start_time": "2023-07-08T14:19:57.950132Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_label_triplet = np.load('train_test_split/train_label_triplet.npy')\n",
    "train_label_triplet = np.load('train_test_split/train_label_triplet_hard13_five_samebrand.npy')\n",
    "test_label_list = np.load('train_test_split/test_label_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6586c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:42.049979Z",
     "start_time": "2023-07-05T11:00:42.047065Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_label_list), train_label_triplet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a0e32",
   "metadata": {},
   "source": [
    "# Triplet Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92742718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:43.843036Z",
     "start_time": "2023-07-05T11:00:43.838242Z"
    }
   },
   "outputs": [],
   "source": [
    "class BrandInfluencerTripletDataset(Dataset):\n",
    "    def __init__(self, brand_node_feat, brand_txt_feat, brand_img_feat,\\\n",
    "                        inf_node_feat, inf_txt_feat, inf_img_feat, label_triplet):\n",
    "        \"\"\"\n",
    "        feature is all ordered by node id.\n",
    "        \"\"\"\n",
    "        self.brand_node_feat = brand_node_feat\n",
    "        self.brand_txt_feat = brand_txt_feat\n",
    "        self.brand_img_feat = brand_img_feat\n",
    "\n",
    "        self.inf_node_feat = inf_node_feat\n",
    "        self.inf_txt_feat = inf_txt_feat\n",
    "        self.inf_img_feat = inf_img_feat\n",
    "        \n",
    "        self.label_triplet = label_triplet       # row: brand, col: inf, val: 1/0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.label_triplet.shape[0] # len of sample triplets\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        brand_node_id = self.label_triplet[index][0]\n",
    "        pos_neg_inf_ids = self.label_triplet[index][1:]       # this is relative node id, which is inf_node_id - 286\n",
    "        \n",
    "        # get the features for the brand\n",
    "        # brand_node_id = index    # the node index of this brand, to get node embedding after GCN and the label_list[brand_node_id] to cal loss\n",
    "        brand_text_feature = self.brand_txt_feat[brand_node_id].reshape(1, -1)   # (1, 200)\n",
    "        brand_image_feature = self.brand_img_feat[brand_node_id].reshape(1, -1)   # (1, 1000)\n",
    "        brand_node_feature = self.brand_node_feat[brand_node_id].reshape(1, -1)\n",
    "\n",
    "        # features of influencers (only of positive and negative sample in this pair)\n",
    "        inf_text_feature = self.inf_txt_feat[pos_neg_inf_ids]\n",
    "        inf_image_feature = self.inf_img_feat[pos_neg_inf_ids]\n",
    "        inf_node_feature = self.inf_node_feat[pos_neg_inf_ids]\n",
    "\n",
    "        return brand_text_feature, brand_image_feature, brand_node_feature,\\\n",
    "            inf_text_feature, inf_image_feature, inf_node_feature,\\\n",
    "            self.label_triplet, brand_node_id\n",
    "            # , brand_node_id, self.brand_num, self.inf_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744a3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:37.759357Z",
     "start_time": "2023-07-05T17:01:37.756825Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03152a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:38.668844Z",
     "start_time": "2023-07-05T17:01:38.666447Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145f22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:39.006934Z",
     "start_time": "2023-07-05T17:01:39.004451Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = BrandInfluencerTripletDataset(train_brand_node_emb, train_brand_text_feature, train_brand_image_feature,\\\n",
    "                                      train_inf_node_emb, train_inf_text_feature, train_inf_image_feature,\\\n",
    "                                       train_label_triplet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa134761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:39.610544Z",
     "start_time": "2023-07-05T17:01:39.607471Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552dce5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:39.998089Z",
     "start_time": "2023-07-05T17:01:39.995724Z"
    },
    "executionInfo": {
     "elapsed": 1866,
     "status": "ok",
     "timestamp": 1684307636878,
     "user": {
      "displayName": "Chuang Iris",
      "userId": "02406937345775007217"
     },
     "user_tz": -480
    },
    "id": "2dZGmWGnu8Cm"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "train_num_workers = 0\n",
    "train_shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f24e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:40.611572Z",
     "start_time": "2023-07-05T17:01:40.607811Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684307639064,
     "user": {
      "displayName": "Chuang Iris",
      "userId": "02406937345775007217"
     },
     "user_tz": -480
    },
    "id": "XsPbrb4Su8Cn"
   },
   "outputs": [],
   "source": [
    "seed = 24\n",
    "same_seeds(24)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=train_shuffle, \n",
    "                          num_workers=train_num_workers, pin_memory=True)\n",
    "#                               num_workers=train_num_workers, worker_init_fn=seed_worker, generator=g, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251a4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce471e1b",
   "metadata": {},
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb5346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:42.330397Z",
     "start_time": "2023-07-05T17:01:42.324791Z"
    }
   },
   "outputs": [],
   "source": [
    "class BrandInfluencerDataset(Dataset):\n",
    "    def __init__(self, brand_node_feat, brand_txt_feat, brand_img_feat,\\\n",
    "                        inf_node_feat, inf_txt_feat, inf_img_feat, label_list):\n",
    "        \"\"\"\n",
    "        feature is all ordered by node id.\n",
    "        \"\"\"\n",
    "\n",
    "        self.brand_node_feat = brand_node_feat\n",
    "        self.brand_txt_feat = brand_txt_feat\n",
    "        self.brand_img_feat = brand_img_feat\n",
    "\n",
    "        self.inf_node_feat = inf_node_feat\n",
    "        self.inf_txt_feat = inf_txt_feat\n",
    "        self.inf_img_feat = inf_img_feat\n",
    "        \n",
    "        self.label_list = label_list       # row: brand, col: inf, val: 1/0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list) # len of brand\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # get the features for the brand\n",
    "        brand_node_id = index    # the node index of this brand, to get node embedding after GCN and the label_list[brand_node_id] to cal loss\n",
    "        brand_text_feature = self.brand_txt_feat[index].reshape(1, -1)   # (1, 200)\n",
    "        brand_image_feature = self.brand_img_feat[index].reshape(1, -1)   # (1, 1000)\n",
    "        brand_node_feature = self.brand_node_feat[index].reshape(1, -1)\n",
    "        # print(brand_text_feature.shape, brand_image_feature.shape)\n",
    "\n",
    "        # features of all influencers\n",
    "        inf_text_feature = self.inf_txt_feat\n",
    "        inf_image_feature = self.inf_img_feat\n",
    "        inf_node_feature = self.inf_node_feat\n",
    "\n",
    "        return brand_text_feature, brand_image_feature, brand_node_feature,\\\n",
    "            inf_text_feature, inf_image_feature, inf_node_feature,\\\n",
    "            self.label_list, brand_node_id\n",
    "            # , brand_node_id, self.brand_num, self.inf_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3683c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:43.166666Z",
     "start_time": "2023-07-05T17:01:43.164154Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = BrandInfluencerDataset(test_brand_node_emb, test_brand_text_feature, test_brand_image_feature,\\\n",
    "                                      test_inf_node_emb, test_inf_text_feature, test_inf_image_feature,\\\n",
    "                                      test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdc195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:43.526261Z",
     "start_time": "2023-07-05T17:01:43.524296Z"
    },
    "id": "J6_5E2uPa4Ip"
   },
   "outputs": [],
   "source": [
    "test_batch_size = 32\n",
    "test_num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8e7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:43.973630Z",
     "start_time": "2023-07-05T17:01:43.969640Z"
    },
    "id": "7AJTxwr6NPsZ"
   },
   "outputs": [],
   "source": [
    "same_seeds(24)\n",
    "# if __name__ == '__main__':\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, \n",
    "                             num_workers=test_num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05eadd9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855f23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:53.710076Z",
     "start_time": "2023-07-05T11:00:53.707548Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.normal_(module.weight, std=0.1)\n",
    "        # init.xavier_uniform_(module.weight)\n",
    "#         nn.init.kaiming_normal_(module.weight)  # he\n",
    "        if module.bias is not None:\n",
    "            init.normal_(module.bias, std=0.1)  \n",
    "            # init.constant_(module.bias, 0)\n",
    "# self.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827795a5",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6789f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:55.140604Z",
     "start_time": "2023-07-05T11:00:55.138489Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684307652527,
     "user": {
      "displayName": "Chuang Iris",
      "userId": "02406937345775007217"
     },
     "user_tz": -480
    },
    "id": "CA95lnQ_o_X7"
   },
   "outputs": [],
   "source": [
    "text_input_size = 19\n",
    "text_layer1_size = 128\n",
    "text_layer2_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71035606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:55.681727Z",
     "start_time": "2023-07-05T11:00:55.677943Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684307652528,
     "user": {
      "displayName": "Chuang Iris",
      "userId": "02406937345775007217"
     },
     "user_tz": -480
    },
    "id": "R9cGo-rOV8PX"
   },
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, input_size=text_input_size, text_layer1_size=text_layer1_size, text_layer2_size=text_layer2_size):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, text_layer1_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(text_layer1_size, text_layer2_size)\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.linear1.weight.dtype)\n",
    "        out = self.linear1(x)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = out.squeeze()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dbc12",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e6bde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:57.257854Z",
     "start_time": "2023-07-05T11:00:57.255389Z"
    }
   },
   "outputs": [],
   "source": [
    "image_input_size = 1365\n",
    "image_layer1_size = 1024\n",
    "image_layer2_size = 1024\n",
    "image_layer3_size = 1024\n",
    "image_layer4_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4e7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:57.780983Z",
     "start_time": "2023-07-05T11:00:57.776545Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, input_size=image_input_size, image_layer1_size=image_layer1_size, image_layer2_size=image_layer2_size, image_layer3_size=image_layer3_size, image_layer4_size=image_layer4_size):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, image_layer1_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(image_layer1_size, image_layer2_size)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.linear3 = nn.Linear(image_layer2_size, image_layer3_size)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.linear4 = nn.Linear(image_layer3_size, image_layer4_size)\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.linear1.weight.dtype)\n",
    "        \n",
    "        out = self.linear1(x)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        out = self.linear3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        out = self.linear4(out)\n",
    "        \n",
    "        out = out.squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46133c2d",
   "metadata": {},
   "source": [
    "## Node (Attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9540c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:59.218436Z",
     "start_time": "2023-07-05T11:00:59.216303Z"
    }
   },
   "outputs": [],
   "source": [
    "node_input_size = 128\n",
    "node_layer1_size = 1024\n",
    "node_layer2_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ab72d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:00:59.492849Z",
     "start_time": "2023-07-05T11:00:59.489096Z"
    }
   },
   "outputs": [],
   "source": [
    "class NodeEncoder(nn.Module):\n",
    "    def __init__(self, input_size=node_input_size, layer1_size=node_layer1_size, layer2_size=node_layer2_size):\n",
    "        super(NodeEncoder, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, layer1_size)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(layer1_size, layer2_size)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.linear1.weight.dtype)\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.linear2(out)\n",
    "        \n",
    "        out = out.squeeze()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6872e12",
   "metadata": {},
   "source": [
    "## Influencer Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b9c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:01:01.080365Z",
     "start_time": "2023-07-05T11:01:01.075646Z"
    }
   },
   "outputs": [],
   "source": [
    "class InfluencerRanker(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InfluencerRanker, self).__init__()\n",
    "        \n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.node_encoder = NodeEncoder()\n",
    "\n",
    "    def forward(self, brand_text_feature, brand_image_feature, brand_node_feature,\\\n",
    "                inf_text_feature, inf_image_feature, inf_node_feature, is_train=True):\n",
    "\n",
    "        if is_train:\n",
    "            batch_size = inf_text_feature.shape[0]\n",
    "            pair_size = inf_text_feature.shape[1]\n",
    "            \n",
    "\n",
    "        # get text embeddings\n",
    "        brand_text_emb = self.text_encoder(brand_text_feature)           # (1, output_size)\n",
    "        inf_text_emb = self.text_encoder(inf_text_feature)\n",
    "\n",
    "        # get image embeddings\n",
    "        brand_image_emb = self.image_encoder(brand_image_feature)        # (1, output_size)\n",
    "        inf_image_emb = self.image_encoder(inf_image_feature)\n",
    "\n",
    "        # get node embeddings\n",
    "        brand_node_emb = self.node_encoder(brand_node_feature)\n",
    "        inf_node_emb = self.node_encoder(inf_node_feature)\n",
    "\n",
    "        \n",
    "        # bilinear pooling\n",
    "        brand_content = torch.mul(brand_text_emb, brand_image_emb)     \n",
    "        inf_content = torch.mul(inf_text_emb, inf_image_emb)\n",
    "\n",
    "        if is_train:\n",
    "            scores_content = torch.sum(brand_content.unsqueeze(1) * inf_content, 2)         # brand_bil -> (batch_size, 1, dim) -> scores: (batch_size, 2)\n",
    "            scores_node = torch.sum(brand_node_emb.unsqueeze(1) * inf_node_emb, 2)  # scores: col 0 是 pos, col 1 是 neg\n",
    "        else:\n",
    "            scores_content = torch.matmul(brand_content, inf_content.transpose(0, 1))\n",
    "            scores_node = torch.matmul(brand_node_emb, inf_node_emb.transpose(0, 1))\n",
    "\n",
    "\n",
    "        return scores_content, scores_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aecbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc256a26",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970f22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:01:03.020253Z",
     "start_time": "2023-07-05T11:01:03.018177Z"
    }
   },
   "outputs": [],
   "source": [
    "margin = 4\n",
    "valid_margin = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0043ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:01:03.277509Z",
     "start_time": "2023-07-05T11:01:03.273826Z"
    }
   },
   "outputs": [],
   "source": [
    "def triplet_ranking_loss_fixed(all_positive_scores, all_negative_scores, margin=margin, valid_margin=valid_margin, times=None):\n",
    "    # Do not need label anymore\n",
    "    # Create the margin tensor\n",
    "    margin1 = (torch.ones(1, all_negative_scores.shape[0]) * margin).to(device)\n",
    "\n",
    "    # Calculate the triplet loss\n",
    "    triplet_loss1 = all_negative_scores - all_positive_scores + margin1\n",
    "    triplet_loss1 = torch.max(triplet_loss1, torch.tensor(0.0))\n",
    "    triplet_loss1 = triplet_loss1.float()\n",
    "    valid_triplets1 = torch.gt(triplet_loss1, torch.tensor(valid_margin))   # if loss > valid_margin, it's a valid loss\n",
    "    valid_triplets1 = valid_triplets1.float()\n",
    "    num_positive_triplets1 = torch.sum(valid_triplets1) # Calculate the number of positive triplets\n",
    "    # print(num_positive_triplets1)\n",
    "\n",
    "    # Calculate the sum of triplet loss\n",
    "    triplet_loss1_sum = torch.sum(triplet_loss1)\n",
    "    epsilon = torch.tensor(1e-16)                      # Add a small epsilon to avoid division by zero\n",
    "    num_positive_triplets1 = num_positive_triplets1 + epsilon\n",
    "\n",
    "    # Calculate the final triplet loss as average of triplet losses\n",
    "    triplet_loss1_avg = triplet_loss1_sum / num_positive_triplets1\n",
    "\n",
    "    return triplet_loss1_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5af23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T11:01:04.068841Z",
     "start_time": "2023-07-05T11:01:04.066354Z"
    }
   },
   "outputs": [],
   "source": [
    "def triplet_cross_entropy(all_positive_scores, all_negative_scores, times=None):\n",
    "    \n",
    "    triplet_ce = -1 * torch.mean( torch.log(all_positive_scores) )\n",
    "\n",
    "    return triplet_ce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d9c8f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219e998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:49.452864Z",
     "start_time": "2023-07-05T17:01:49.450212Z"
    }
   },
   "outputs": [],
   "source": [
    "# check device\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa108d19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:50.470194Z",
     "start_time": "2023-07-05T17:01:50.467620Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "# same_seeds(24)\n",
    "\n",
    "# get device \n",
    "device = get_device()\n",
    "# device = 'cuda:1'\n",
    "print(f'DEVICE: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1aac17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:53.339229Z",
     "start_time": "2023-07-05T17:01:53.336787Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.002\n",
    "# weight_decayx = 0.001\n",
    "dropout_prob = 0.5\n",
    "l1_lambda = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580a2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:53.825758Z",
     "start_time": "2023-07-05T17:01:53.744720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model and loss function\n",
    "model = InfluencerRanker()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d582b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:54.230992Z",
     "start_time": "2023-07-05T17:01:54.227463Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = triplet_ranking_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97cb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:54.637191Z",
     "start_time": "2023-07-05T17:01:54.634427Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c717b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:55.059953Z",
     "start_time": "2023-07-05T17:01:55.057141Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7415944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:55.472963Z",
     "start_time": "2023-07-05T17:01:55.469556Z"
    }
   },
   "outputs": [],
   "source": [
    "train_triplet_label = torch.from_numpy(train_label_triplet).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56172ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:01:55.923128Z",
     "start_time": "2023-07-05T17:01:55.920085Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe581ab",
   "metadata": {
    "id": "N-cN_z-bXClK"
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397b0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:02:29.438686Z",
     "start_time": "2023-07-05T17:02:29.436356Z"
    },
    "id": "0hMUt_BjoUk3"
   },
   "outputs": [],
   "source": [
    "model_name = \"bamir\"\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d8d3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:02:30.037814Z",
     "start_time": "2023-07-05T17:02:30.034948Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f7d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:02:33.038546Z",
     "start_time": "2023-07-05T17:02:33.028247Z"
    }
   },
   "outputs": [],
   "source": [
    "# 順便存每個 epoch 的 testing 結果\n",
    "test_fixed_label_list = torch.from_numpy(test_label_list).to(device)\n",
    "test_inf_text_feature = test_inf_text_feature.to(device)\n",
    "test_inf_image_feature = test_inf_image_feature.to(device)\n",
    "test_inf_node_feature = test_inf_node_emb.to(device)\n",
    "test_brand_text_feature = test_brand_text_feature.to(device)\n",
    "test_brand_image_feature = test_brand_image_feature.to(device)\n",
    "test_brand_node_feature = test_brand_node_emb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623bbe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T17:02:33.429079Z",
     "start_time": "2023-07-05T17:02:33.426622Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_list = []\n",
    "rec10_list = []\n",
    "rec50_list = []\n",
    "mrr_list = []\n",
    "map_list = []\n",
    "medr_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029202f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T19:03:09.547355Z",
     "start_time": "2023-07-05T17:02:35.631899Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_loss_values = []\n",
    "all_all_scores = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    if epoch == 50: # save 100 epochs as another file\n",
    "        model_name = model_name[:-2]+'100'\n",
    "    pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "    for batch_id, batch in pbar:\n",
    "\n",
    "        brand_text_feature, brand_image_feature, brand_node_feature,\\\n",
    "            inf_text_feature, inf_image_feature, inf_node_feature, _, _ = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move input data to GPU\n",
    "        brand_text_feature = brand_text_feature.to(device)\n",
    "        brand_image_feature = brand_image_feature.to(device)\n",
    "        brand_node_feature = brand_node_feature.to(device)\n",
    "        inf_text_feature = inf_text_feature.to(device)\n",
    "        inf_image_feature = inf_image_feature.to(device)\n",
    "        inf_node_feature = inf_node_feature.to(device)\n",
    "\n",
    "        scores_content, scores_node = model(brand_text_feature, brand_image_feature, brand_node_feature,\\\n",
    "                       inf_text_feature, inf_image_feature, inf_node_feature)\n",
    "        \n",
    "        batch_loss_content = criterion(scores_content[:, 0], scores_content[:, 1], margin=4, times=None)\n",
    "        batch_loss_node = criterion(scores_node[:, 0], scores_node[:, 1], margin=2, times=None)\n",
    "\n",
    "        # global cross entropy loss\n",
    "        global_score = torch.softmax((scores_content + scores_node), dim=1)\n",
    "        epsilon = 1e-16\n",
    "        global_score = global_score + epsilon\n",
    "        \n",
    "        global_loss = triplet_cross_entropy(global_score[:, 0::2], global_score[:, 1::2], times=None)\n",
    "\n",
    "        # define batch loss\n",
    "        batch_loss = batch_loss_content + batch_loss_node + global_loss\n",
    "\n",
    "        # L1 regularization\n",
    "        l1_reg = torch.tensor(0., requires_grad=True)\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                l1_reg = l1_reg + torch.norm(param, p=1)\n",
    "        batch_loss += l1_lambda * l1_reg\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += batch_loss.item()\n",
    "\n",
    "        description = f'Epoch {epoch+1}/{num_epochs}, Batch {batch_id+1}/{len(train_dataloader)}, Gloabl Loss: {batch_loss:.4f}, Separate Loss: {batch_loss_content:.4f}, {batch_loss_node:.4f}, {global_loss:.4f} L1: {l1_lambda * l1_reg}'\n",
    "        pbar.set_description(description)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = running_loss / len(train_dataloader)    # average loss of this epoch (/ number of batch)\n",
    "    train_loss_values.append(train_loss)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    ################ Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores_content, scores_node = model(test_brand_text_feature, test_brand_image_feature, test_brand_node_feature,\\\n",
    "                           test_inf_text_feature, test_inf_image_feature, test_inf_node_feature, is_train=False)\n",
    "        all_scores = scores_content + scores_node\n",
    "        all_all_scores.append(all_scores)\n",
    "        print(all_scores.shape)\n",
    "    auc, rec10, rec50, mrr, map_, medr = cal_metrics(test_fixed_label_list.cpu(), all_scores.cpu())\n",
    "    auc_list.append(auc)\n",
    "    rec10_list.append(rec10)\n",
    "    rec50_list.append(rec50)\n",
    "    mrr_list.append(mrr)\n",
    "    map_list.append(map_)\n",
    "    medr_list.append(medr)\n",
    "\n",
    "    print(f\"***** Epoch {epoch+1}: Train Loss={train_loss:.4f}, lr={scheduler.get_last_lr()[0]} *****\")\n",
    "    checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'losses': train_loss_values,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'all_all_scores': all_all_scores\n",
    "        }\n",
    "    if save:\n",
    "        torch.save(checkpoint, 'models/'+model_name+'.pth')\n",
    "        if (epoch+1) == 40:\n",
    "            torch.save(checkpoint, 'models/'+model_name[:-2]+'40.pth')\n",
    "\n",
    "all_all_scores = torch.stack(all_all_scores)\n",
    "if save:\n",
    "    with open('models/'+model_name+\"_architecture.txt\", \"w\") as file:\n",
    "        print(model, file=file)\n",
    "    torch.save(all_all_scores, 'models/'+model_name+\"predict.pt\")\n",
    "# Create a plot\n",
    "plt.plot(train_loss_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "\n",
    "# Show or save the plot\n",
    "if save:\n",
    "    plt.savefig('models/'+model_name+'.png')\n",
    "plt.show()  # Show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570bf01",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b80b0",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auc_df = pd.read_csv('train_test_split/test_auc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate Recall@k\n",
    "def recall_at_k(scores, labels, k):\n",
    "    \"\"\"\n",
    "    Calculate Recall@k metric.\n",
    "    \n",
    "    Args:\n",
    "        scores (np.ndarray): 2D array of shape (num_samples, num_classes) containing the predicted scores.\n",
    "        labels (np.ndarray): 2D array of shape (num_samples, num_classes) containing the binary labels.\n",
    "        k (int): The value of k for Recall@k.\n",
    "        \n",
    "    Returns:\n",
    "        float: The Recall@k score.\n",
    "    \"\"\"\n",
    "    # Sort the scores in descending order\n",
    "    sorted_indices = np.argsort(-scores, axis=1)\n",
    "    \n",
    "    # Get the top k predicted labels for each sample\n",
    "    top_k_indices = sorted_indices[:, :k]\n",
    "    \n",
    "    # Calculate the number of true positive predictions for each sample\n",
    "    # true_positives = np.sum(labels[np.arange(labels.shape[0])[:, None], top_k_indices], axis=1)\n",
    "    true_positives = torch.sum(labels[torch.arange(labels.shape[0])[:, None], top_k_indices], dim=1)\n",
    "    \n",
    "    # Calculate the total number of positive labels for each sample\n",
    "    total_positives = torch.sum(labels, axis=1)\n",
    "    \n",
    "    # Calculate Recall@k\n",
    "    recall_at_k = torch.mean(true_positives / total_positives)\n",
    "    \n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af932ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(label_list, scores): # input should be cpu\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(label_list.ravel(), scores.ravel())\n",
    "#     print(\"AUC:\", auc)\n",
    "\n",
    "    # Calculate Recall@k (e.g. k = 5)\n",
    "    rec10 = recall_at_k(scores, label_list, 10)\n",
    "#     print(\"Recall@10:\", rec10.item())\n",
    "    rec50 = recall_at_k(scores, label_list, 50)\n",
    "#     print(\"Recall@50:\", rec50.item())\n",
    "\n",
    "    # Calculate MRR (Mean Reciprocal Rank)\n",
    "    sorted_indices = np.argsort(-scores, axis=1)\n",
    "    #   ranks = np.array([np.where(sorted_indices[i] == np.argmax(label_list[i]))[0][0] + 1 for i in range(label_list.shape[0])])\n",
    "    ranks = np.array([np.argmax(np.isin(sorted_indices[i], np.where(label_list[i] == 1)))+1 for i in range(label_list.shape[0])])\n",
    "    mrr = np.mean(1 / ranks)\n",
    "#     print(\"MRR:\", mrr)\n",
    "\n",
    "    # Calculate MAP (Mean Average Precision)\n",
    "    map_ = np.mean([average_precision_score(label_list[i], scores[i]) for i in range(label_list.shape[0])])\n",
    "#     print(\"MAP:\", map_)\n",
    "\n",
    "    # Calculate MedR (Median Rank)\n",
    "    medr = np.median(ranks)\n",
    "#     print(\"MedR:\", medr)\n",
    "    \n",
    "    display(pd.DataFrame({'AUC': [auc], 'R@10': [rec10.item()], 'R@50': [rec50.item()], 'MRR': [mrr], 'MAP': [map_], 'MedR': [medr]}))\n",
    "\n",
    "    return auc, rec10.item(), rec50.item(), mrr, map_, medr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_auc(score, brand_node_id, inf_node_id, auc_df):\n",
    "    # AUC cAUC\n",
    "    err = 0\n",
    "    AUC = 0.0\n",
    "    AUC_all = 0.0\n",
    "    cAUC = 0.0\n",
    "    cAUC_all = 0.0\n",
    "\n",
    "    brand_num = score.shape[0]\n",
    "\n",
    "    # iterate through the dataframe\n",
    "    for i in range(len(auc_df)):\n",
    "        AUC_all += 1\n",
    "        score1 = 0.0\n",
    "        score2 = 0.0\n",
    "        \n",
    "        b1_node_id = brand_node_id[auc_df['b1'][i]]  # brand_to_node[brand_id]\n",
    "        i1_node_id = inf_node_id[auc_df['i1'][i]] - brand_num\n",
    "        b2_node_id = brand_node_id[auc_df['b2'][i]]\n",
    "        i2_node_id = inf_node_id[auc_df['i2'][i]] - brand_num\n",
    "        c1 = auc_df['c1'][i]\n",
    "        c2 = auc_df['c2'][i]\n",
    "        \n",
    "        score1 = score[b1_node_id][i1_node_id]\n",
    "        score2 = score[b1_node_id][i2_node_id]\n",
    "        # print(score1, score2)\n",
    "        \n",
    "        if (score1 == 0.0 or score2 == 0.0):\n",
    "            err += 1\n",
    "        if (c1 == c2):\n",
    "            cAUC_all += 1\n",
    "        if (score1 > score2):\n",
    "            AUC += 1\n",
    "            if (c1 == c2):\n",
    "                # print(score1, score2)\n",
    "                cAUC += 1\n",
    "\n",
    "    print('AUC:', AUC/AUC_all)\n",
    "    print('cAUC:', cAUC/cAUC_all)\n",
    "    print(err)\n",
    "    print(AUC_all, cAUC_all)\n",
    "    return AUC / AUC_all, cAUC / cAUC_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f56b5",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1c06c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T08:51:42.800361Z",
     "start_time": "2023-06-22T08:51:42.796497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the fixed feature\n",
    "test_fixed_label_list = torch.from_numpy(test_label_list).to(device)\n",
    "test_inf_text_feature = test_inf_text_feature.to(device)\n",
    "test_inf_image_feature = test_inf_image_feature.to(device)\n",
    "test_inf_node_feature = test_inf_node_emb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278288c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T08:51:44.196935Z",
     "start_time": "2023-06-22T08:51:43.884751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_scores = [0 for _ in range(len(test_dataset))]\n",
    "    # all_scores = []\n",
    "    all_labels = []\n",
    "    for i, (brand_text_feature, brand_image_feature, brand_node_feature,\\\n",
    "            _, _, _, _, brand_node_id) in enumerate(test_dataloader):\n",
    "        \n",
    "        brand_text_feature = brand_text_feature.to(device)\n",
    "        brand_image_feature = brand_image_feature.to(device)\n",
    "        brand_node_feature = brand_node_feature.to(device)\n",
    "        brand_node_id = brand_node_id.to(device)\n",
    "        # print(brand_node_id.shape)\n",
    "\n",
    "        labels = test_fixed_label_list[brand_node_id]\n",
    "        scores_content, scores_node = model(brand_text_feature, brand_image_feature, brand_node_feature,\\\n",
    "                       test_inf_text_feature, test_inf_image_feature, test_inf_node_feature, is_train=False)\n",
    "        \n",
    "        # all_labels.append(labels)\n",
    "        # all_scores.append(scores)\n",
    "        for i in range(brand_node_id.shape[0]):\n",
    "            bid = brand_node_id[i].item()\n",
    "            all_scores[bid] = scores_content[i] + scores_node[i]\n",
    "\n",
    "    all_scores = torch.stack(all_scores, dim=0) \n",
    "    print(all_scores.shape)\n",
    "    ranked_influencers = torch.argsort(all_scores, dim=1, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef2195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T14:20:03.461690Z",
     "start_time": "2023-07-08T14:20:03.380434Z"
    }
   },
   "outputs": [],
   "source": [
    "cal_metrics(test_fixed_label_list.cpu(), all_scores.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0643fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T14:23:14.231647Z",
     "start_time": "2023-07-08T14:20:04.352084Z"
    }
   },
   "outputs": [],
   "source": [
    "cal_auc(all_scores, test_brand_node_id, test_inf_node_id, test_auc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f09898",
   "metadata": {},
   "source": [
    "## Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9401aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T10:10:12.429347Z",
     "start_time": "2023-06-26T10:10:12.425944Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'bamir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9fbe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T10:10:12.985930Z",
     "start_time": "2023-06-26T10:10:12.979269Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = 'models/'+ model_name +'.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa6e67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T10:10:13.948903Z",
     "start_time": "2023-06-26T10:10:13.746560Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a100161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T10:10:16.260681Z",
     "start_time": "2023-06-26T10:10:16.062960Z"
    }
   },
   "outputs": [],
   "source": [
    "model = InfluencerRanker().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b3736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T10:10:16.748611Z",
     "start_time": "2023-06-26T10:10:16.738905Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ab77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
